
<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-B139P18WHM"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-B139P18WHM');
    </script>
    
    <title>Counterfactual Fairness &#8212; DoWhy  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=949a1ff5" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css?v=2aa19091" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script src="../_static/jquery.js?v=5d32c60e"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=0c6e27e1"></script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'example_notebooks/counterfactual_fairness_dowhy';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Causal attribution to sales growth and spend intervention" href="sales_attribution_intervention.html" />
    <link rel="prev" title="Falsification of User-Given Directed Acyclic Graphs" href="gcm_falsify_dag.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
<div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
    <span class="fa-solid fa-bars"></span>
  </label>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/dowhy-logo-small.png" class="logo__image only-light" alt="DoWhy  documentation - Home"/>
    <script>document.write(`<img src="../_static/dowhy-logo-small.png" class="logo__image only-dark" alt="DoWhy  documentation - Home"/>`);</script>
  
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../getting_started/index.html">
                        Getting Started
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../user_guide/index.html">
                        User Guide
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="nb_index.html">
                        Examples
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../cite.html">
                        Citing this package
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../contributing.html">
                        Contributing
                      </a>
                    </li>
                
            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../dowhy.html">
                        dowhy package
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../code_repo.html">
                        Release notes
                      </a>
                    </li>
                
                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
        </div>
      
      
        <div class="navbar-item"><div class="dropdown" id="version_switcher">
    <button type="button" class="btn btn-sm navbar-btn dropdown-toggle" id="version_switcher_button" data-toggle="dropdown">
        main
        <span class="caret"></span>
    </button>
    <div id="version_switcher_menu" class="dropdown-menu list-group-flush py-0" aria-labelledby="version_switcher_button">
        <dl>
            <dt>Releases</dt>
            <dd><a href="/dowhy/v0.9.1/index.html">v0.9.1</a></dd>
            <dd><a href="/dowhy/v0.9/index.html">v0.9</a></dd>
            <dd><a href="/dowhy/v0.8/index.html">v0.8</a></dd>
            <dd><a href="/dowhy/v0.7.1/index.html">v0.7.1</a></dd>
            <dd><a href="/dowhy/v0.7/index.html">v0.7</a></dd>
            <dd><a href="/dowhy/v0.6/index.html">v0.6</a></dd>
            <dd><a href="/dowhy/v0.5.1/index.html">v0.5.1</a></dd>
            <dd><a href="/dowhy/v0.5/index.html">v0.5</a></dd>
            <dd><a href="/dowhy/v0.4/index.html">v0.4</a></dd>
            <dd><a href="/dowhy/v0.2/index.html">v0.2</a></dd>
            <dd><a href="/dowhy/v0.12/index.html">v0.12</a></dd>
            <dd><a href="/dowhy/v0.11.1/index.html">v0.11.1</a></dd>
            <dd><a href="/dowhy/v0.11/index.html">v0.11</a></dd>
            <dd><a href="/dowhy/v0.10.1/index.html">v0.10.1</a></dd>
            <dd><a href="/dowhy/v0.10/index.html">v0.10</a></dd>
            <dd><a href="/dowhy/v0.1.1-alpha/index.html">v0.1.1-alpha</a></dd>
        </dl>        
        <dl>
            <dt>Branches</dt>
            <dd><a href="">main</a></dd>
        </dl>        
    </div>
</div></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
    </div>
  

  
    <label class="sidebar-toggle secondary-toggle" for="__secondary" tabindex="0">
      <span class="fa-solid fa-outdent"></span>
    </label>
  
</div>

    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          <div class="navbar-item">
<nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../getting_started/index.html">
                        Getting Started
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../user_guide/index.html">
                        User Guide
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="nb_index.html">
                        Examples
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../cite.html">
                        Citing this package
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../contributing.html">
                        Contributing
                      </a>
                    </li>
                
            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links-2">
                    More
                </button>
                <ul id="pst-nav-more-links-2" class="dropdown-menu">
                    
                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../dowhy.html">
                        dowhy package
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link dropdown-item nav-internal" href="../code_repo.html">
                        Release notes
                      </a>
                    </li>
                
                </ul>
            </li>
            
  </ul>
</nav></div>
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item"><div class="dropdown" id="version_switcher">
    <button type="button" class="btn btn-sm navbar-btn dropdown-toggle" id="version_switcher_button" data-toggle="dropdown">
        main
        <span class="caret"></span>
    </button>
    <div id="version_switcher_menu" class="dropdown-menu list-group-flush py-0" aria-labelledby="version_switcher_button">
        <dl>
            <dt>Releases</dt>
            <dd><a href="/dowhy/v0.9.1/index.html">v0.9.1</a></dd>
            <dd><a href="/dowhy/v0.9/index.html">v0.9</a></dd>
            <dd><a href="/dowhy/v0.8/index.html">v0.8</a></dd>
            <dd><a href="/dowhy/v0.7.1/index.html">v0.7.1</a></dd>
            <dd><a href="/dowhy/v0.7/index.html">v0.7</a></dd>
            <dd><a href="/dowhy/v0.6/index.html">v0.6</a></dd>
            <dd><a href="/dowhy/v0.5.1/index.html">v0.5.1</a></dd>
            <dd><a href="/dowhy/v0.5/index.html">v0.5</a></dd>
            <dd><a href="/dowhy/v0.4/index.html">v0.4</a></dd>
            <dd><a href="/dowhy/v0.2/index.html">v0.2</a></dd>
            <dd><a href="/dowhy/v0.12/index.html">v0.12</a></dd>
            <dd><a href="/dowhy/v0.11.1/index.html">v0.11.1</a></dd>
            <dd><a href="/dowhy/v0.11/index.html">v0.11</a></dd>
            <dd><a href="/dowhy/v0.10.1/index.html">v0.10.1</a></dd>
            <dd><a href="/dowhy/v0.10/index.html">v0.10</a></dd>
            <dd><a href="/dowhy/v0.1.1-alpha/index.html">v0.1.1-alpha</a></dd>
        </dl>        
        <dl>
            <dt>Branches</dt>
            <dd><a href="">main</a></dd>
        </dl>        
    </div>
</div></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Introductory examples</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dowhy_simple_example.html">Basic Example for Calculating the Causal Effect</a></li>
<li class="toctree-l1"><a class="reference internal" href="gcm_basic_example.html">Basic Example for Graphical Causal Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="gcm_draw_samples.html">Basic Example for generating samples from a GCM</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_confounder_example.html">Confounding Example: Finding causal effects from observed data</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy-conditional-treatment-effects.html">Conditional Average Treatment Effects (CATE) with DoWhy and EconML</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial-causalinference-machinelearning-using-dowhy-econml.html">Tutorial on Causal Inference and its Connections to Machine Learning (Using DoWhy+EconML)</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_mediation_analysis.html">Mediation analysis with DoWhy: Direct and Indirect Effects</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_refuter_notebook.html">Iterating over multiple refutation tests</a></li>
<li class="toctree-l1"><a class="reference internal" href="do_sampler_demo.html">Do-sampler Introduction</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Real world-inspired examples</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="DoWhy-The%20Causal%20Story%20Behind%20Hotel%20Booking%20Cancellations.html">Exploring Causes of Hotel Booking Cancellations</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_example_effect_of_memberrewards_program.html">Estimating the Effect of a Member Rewards Program</a></li>
<li class="toctree-l1"><a class="reference internal" href="gcm_online_shop.html">Causal Attributions and Root-Cause Analysis in an Online Shop</a></li>

<li class="toctree-l1"><a class="reference internal" href="gcm_rca_microservice_architecture.html">Finding the Root Cause of Elevated Latencies in a Microservice Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="gcm_401k_analysis.html">Impact of 401(k) eligibility on net financial assets</a></li>
<li class="toctree-l1"><a class="reference internal" href="gcm_supply_chain_dist_change.html">Finding Root Causes of Changes in a Supply Chain</a></li>
<li class="toctree-l1"><a class="reference internal" href="gcm_icc.html">Estimating intrinsic causal influences in real-world examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="gcm_counterfactual_medical_dry_eyes.html">Counterfactual Analysis in a Medical Case</a></li>
<li class="toctree-l1"><a class="reference internal" href="gcm_falsify_dag.html">Falsification of User-Given Directed Acyclic Graphs</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Counterfactual Fairness</a></li>






<li class="toctree-l1"><a class="reference internal" href="sales_attribution_intervention.html">Causal attribution to sales growth and spend intervention</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Examples on benchmarks datasets</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dowhy_ihdp_data_example.html">DoWhy example on ihdp (Infant Health and Development Program) dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_lalonde_example.html">DoWhy example on the Lalonde dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_refutation_testing.html">Applying refutation tests to the Lalonde and IHDP datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="gcm_401k_analysis.html">Impact of 401(k) eligibility on net financial assets</a></li>
<li class="toctree-l1"><a class="reference internal" href="prediction/dowhy_causal_prediction_demo.html">Demo for DoWhy Causal Prediction on MNIST</a></li>
<li class="toctree-l1"><a class="reference internal" href="lalonde_pandas_api.html">Lalonde Pandas API Example</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Counterfactual Fairness</a></li>






<li class="toctree-l1"><a class="reference internal" href="dowhy_twins_example.html">DoWhy example on Twins dataset</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Modeling and refuting causal assumptions</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="load_graph_example.html">Different ways to load an input graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_causal_discovery_example.html">Causal Discovery example</a></li>




<li class="toctree-l1"><a class="reference internal" href="gcm_falsify_dag.html">Falsification of User-Given Directed Acyclic Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="sensitivity_analysis_testing.html">Sensitivity Analysis for Regression Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="sensitivity_analysis_nonparametric_estimators.html">Sensitivity analysis for non-parametric causal estimators</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_refuter_notebook.html">Iterating over multiple refutation tests</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_refuter_assess_overlap.html">Assessing Support and Overlap with OverRule</a></li>



<li class="toctree-l1"><a class="reference internal" href="dowhy_ranking_methods.html">Ranking of estimation methods for a given dataset</a></li>


<li class="toctree-l1"><a class="reference internal" href="dowhy_demo_dummy_outcome_refuter.html">A Simple Example on Creating a Custom Refutation Using User-Defined Outcome Functions</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Miscellaneous</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dowhy_estimation_methods.html">DoWhy: Different estimation methods for causal inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy-simple-iv-example.html">Simple example on using Instrumental Variables method for estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_interpreter.html">DoWhy: Interpreters for Causal Estimators</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_mediation_analysis.html">Mediation analysis with DoWhy: Direct and Indirect Effects</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_multiple_treatments.html">Estimating effect of multiple treatments</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_efficient_backdoor_example.html">Finding optimal adjustment sets</a></li>
<li class="toctree-l1"><a class="reference internal" href="identifying_effects_using_id_algorithm.html">Identifying Effect using ID Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_optimize_backdoor_example.html">Example to demonstrate optimized backdoor variable search for Causal Identification</a></li>
<li class="toctree-l1"><a class="reference internal" href="dowhy_functional_api.html">Functional API Preview</a></li>

<li class="toctree-l1"><a class="reference internal" href="dowhy_causal_api.html">Demo for the DoWhy causal API</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="nb_index.html" class="nav-link">Example notebooks</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Counterfactu...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="Counterfactual-Fairness">
<h1>Counterfactual Fairness<a class="headerlink" href="#Counterfactual-Fairness" title="Permalink to this heading">#</a></h1>
<p>This post introduces and replicates counterfactual fairness as proposed by Kusner et al. (2018) using DoWhy.</p>
<p>Counterfactual fairness serves as an individual-level measure of causal fairness, capturing the notion that an estimator’s decision is deemed fair for an individual if it remains consistent both in (a) the actual world and (b) a counterfactual world where the individual is associated with a different demographic group.</p>
<section id="When-to-apply-counterfactual-fairness?">
<h2>When to apply counterfactual fairness?<a class="headerlink" href="#When-to-apply-counterfactual-fairness?" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>To assess whether a prediction is individually causally fair, i.e., if a prediction is fair for a given individual <code class="docutils literal notranslate"><span class="pre">i</span></code>.</p></li>
</ol>
</section>
<section id="What-is-required-to-estimate-counterfactual-fairness?">
<h2>What is required to estimate counterfactual fairness?<a class="headerlink" href="#What-is-required-to-estimate-counterfactual-fairness?" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Dataset with protected attributes or proxy variables.</p></li>
<li><p>A Structural Causal Model (SCM) : discovered either using a SCM discovery algorithm or through expert driven caual DAG creation.</p></li>
</ol>
<section id="Notation">
<h3>Notation<a class="headerlink" href="#Notation" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>A: Set of protected attributes of an individual, representing variables that must not be subject to discrimination.</p></li>
<li><p>a: Actual value taken by the protected attribute in the real world.</p></li>
<li><p>a’: Counterfactual (/flipped) value for the protected attribute.</p></li>
<li><p>X: Other observable attributes of any particular individual.</p></li>
<li><p>U: The set of relevant latent attributes that are not observed.</p></li>
<li><p>Y: The outcome to be predicted, which might be contaminated with historical biases.</p></li>
<li><p><span class="math notranslate nohighlight">\(\hat{Y}\)</span>: The predictor, a random variable dependent on A, X, and U, produced by a machine learning algorithm as a prediction of Y.</p></li>
</ul>
<p>Following Pearl, a structural causal model M is defined as a 4-tuple (U, V, F, P(u)), which can be represented using a directed acyclic graph (DAG) where:</p>
<ul class="simple">
<li><p>U: Set of exogenous (unobserved) variables determined by factors outside of the model.</p></li>
<li><p>V: Set {V1 … Vn} of endogenous (observed) variables completely determined by variables in the model (both U and V). Note: V includes both features X and output Y.</p></li>
<li><p>F: Set of structural equations {f1 … fn}, where each fi is a process by which Vi is assigned a value fi(v,u) in response to the current (relevant) values of U &amp; V.</p></li>
<li><p>P(u): (Prior) distribution over U.</p></li>
<li><p>do(Zi = z): (Do) intervention (Pearl 2000, Ch. 3), representing a manipulation of M where the values of the chosen intervention variables Z (a subset of V) are set to a constant value z, regardless of how the values are ordinarily generated by the DAG. This captures the idea of an agent, external to the system, modifying the system by forcefully assigning value z to Zi (for example, as in a randomized experiment). In the fairness literature, Z often comprises protected attributes like race,
gender, etc.</p></li>
</ul>
<p>M is causal because given P(U), following a do intervention on a subset Z, we can derive the distribution over the remaining, non-intervened variables in V.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">namedtuple</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">stats</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sklearn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.neighbors</span><span class="w"> </span><span class="kn">import</span> <span class="n">KernelDensity</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.mixture</span><span class="w"> </span><span class="kn">import</span> <span class="n">GaussianMixture</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">LinearRegression</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseEstimator</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">dowhy</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">dowhy.gcm</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">gcm</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">networkx</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nx</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn</span><span class="w"> </span><span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">metrics</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.base</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseEstimator</span>


<span class="k">def</span><span class="w"> </span><span class="nf">analyse_counterfactual_fairness</span><span class="p">(</span>
    <span class="n">df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">estimator</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">BaseEstimator</span><span class="p">],</span>
    <span class="n">protected_attrs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">dag</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">],</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">target</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">disadvantage_group</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
    <span class="n">intersectional</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">return_cache</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates Counterfactual Fairness following Kusner et al. (2018)</span>
<span class="sd">    Reference - https://arxiv.org/pdf/1703.06856.pdf</span>

<span class="sd">    Args:</span>
<span class="sd">        df (pd.DataFrame): Pandas DataFrame containing non-factorized/dummified versions of categorical</span>
<span class="sd">            variables, the predicted ylabel, and other variables consumed by the predictive model.</span>
<span class="sd">        estimator (Union[BaseEstimator]): Predictive model to be used for generating the output.</span>
<span class="sd">        protected_attrs (List[str]): List of protected attributes in the dataset.</span>
<span class="sd">        dag (List[Tuple]): List of tuples representing the Directed Acyclic Graph (DAG) structure.</span>
<span class="sd">        X (List[str]): List of features to be used by the estimator.</span>
<span class="sd">        target (str): Name of the target variable in df.</span>
<span class="sd">        disadvantage_group (dict): Dictionary specifying the disadvantaged group for each protected attribute.</span>
<span class="sd">        intersectional (bool, optional): If True, considers intersectional fairness. Defaults to False.</span>
<span class="sd">        return_cache (bool, optional): If True, returns the counterfactual values with observed and</span>
<span class="sd">            counterfactual protected attribute interventions for each row in df. Defaults to False.</span>

<span class="sd">    Returns:</span>
<span class="sd">        counterfactual_fairness (Union[float, Tuple[float, pd.DataFrame, pd.DataFrame]]):</span>
<span class="sd">            - If return_cache is False, returns the calculated counterfactual fairness as a float.</span>
<span class="sd">            - If return_cache is True, returns a tuple containing counterfactual fairness as a float,</span>
<span class="sd">              DataFrame df_obs with observed counterfactual values, and DataFrame df_cf with perturbered counterfactual values.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">invt_local_causal_model</span> <span class="o">=</span> <span class="n">gcm</span><span class="o">.</span><span class="n">InvertibleStructuralCausalModel</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">DiGraph</span><span class="p">(</span><span class="n">dag</span><span class="p">))</span>
    <span class="n">gcm</span><span class="o">.</span><span class="n">auto</span><span class="o">.</span><span class="n">assign_causal_mechanisms</span><span class="p">(</span><span class="n">invt_local_causal_model</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span>

    <span class="n">gcm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">invt_local_causal_model</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span>

    <span class="n">df_cf</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="n">df_obs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>

    <span class="n">do_val_observed</span> <span class="o">=</span> <span class="p">{</span><span class="n">protected_attr</span><span class="p">:</span> <span class="s2">&quot;observed&quot;</span> <span class="k">for</span> <span class="n">protected_attr</span> <span class="ow">in</span> <span class="n">protected_attrs</span><span class="p">}</span>
    <span class="n">do_val_counterfact</span> <span class="o">=</span> <span class="p">{</span><span class="n">protected_attr</span><span class="p">:</span> <span class="s2">&quot;cf&quot;</span> <span class="k">for</span> <span class="n">protected_attr</span> <span class="ow">in</span> <span class="n">protected_attrs</span><span class="p">}</span>

    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>

        <span class="n">do_val_obs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">protected_attr</span><span class="p">,</span> <span class="n">intervention_type</span> <span class="ow">in</span> <span class="n">do_val_observed</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">intervention_val</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span>
                <span class="n">row</span><span class="p">[</span><span class="n">protected_attr</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">intervention_type</span> <span class="o">==</span> <span class="s2">&quot;observed&quot;</span>
                <span class="k">else</span> <span class="mi">1</span> <span class="o">-</span> <span class="nb">float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="n">protected_attr</span><span class="p">])</span>
            <span class="p">)</span>
            <span class="n">do_val_obs</span><span class="p">[</span><span class="n">protected_attr</span><span class="p">]</span> <span class="o">=</span> <span class="n">_wrapper_lambda_fn</span><span class="p">(</span><span class="n">intervention_val</span><span class="p">)</span>

        <span class="n">do_val_cf</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">protected_attr</span><span class="p">,</span> <span class="n">intervention_type</span> <span class="ow">in</span> <span class="n">do_val_counterfact</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">intervention_val</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span>
                <span class="nb">float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="n">protected_attr</span><span class="p">])</span>
                <span class="k">if</span> <span class="n">intervention_type</span> <span class="o">==</span> <span class="s2">&quot;observed&quot;</span>
                <span class="k">else</span> <span class="mi">1</span> <span class="o">-</span> <span class="nb">float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="n">protected_attr</span><span class="p">])</span>
            <span class="p">)</span>
            <span class="n">do_val_cf</span><span class="p">[</span><span class="n">protected_attr</span><span class="p">]</span> <span class="o">=</span> <span class="n">_wrapper_lambda_fn</span><span class="p">(</span><span class="n">intervention_val</span><span class="p">)</span>

        <span class="n">counterfactual_samples_obs</span> <span class="o">=</span> <span class="n">gcm</span><span class="o">.</span><span class="n">counterfactual_samples</span><span class="p">(</span>
            <span class="n">invt_local_causal_model</span><span class="p">,</span> <span class="n">do_val_obs</span><span class="p">,</span> <span class="n">observed_data</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">row</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="p">)</span>

        <span class="n">counterfactual_samples_cf</span> <span class="o">=</span> <span class="n">gcm</span><span class="o">.</span><span class="n">counterfactual_samples</span><span class="p">(</span>
            <span class="n">invt_local_causal_model</span><span class="p">,</span> <span class="n">do_val_cf</span><span class="p">,</span> <span class="n">observed_data</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">row</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="p">)</span>

        <span class="n">df_cf</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_cf</span><span class="p">,</span> <span class="n">counterfactual_samples_cf</span><span class="p">])</span>
        <span class="n">df_obs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_obs</span><span class="p">,</span> <span class="n">counterfactual_samples_obs</span><span class="p">])</span>

    <span class="n">df_cf</span> <span class="o">=</span> <span class="n">df_cf</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">df_obs</span> <span class="o">=</span> <span class="n">df_obs</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="s2">&quot;predict_proba&quot;</span><span class="p">):</span>
        <span class="c1"># 1. Samples from the causal model based on the observed race</span>
        <span class="n">lr_observed</span> <span class="o">=</span> <span class="n">estimator</span><span class="p">()</span>
        <span class="n">lr_observed</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_obs</span><span class="p">[</span><span class="n">X</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">),</span> <span class="n">df</span><span class="p">[</span><span class="n">target</span><span class="p">])</span>
        <span class="n">df_obs</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;preds&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr_observed</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">df_obs</span><span class="p">[</span><span class="n">X</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">))[:,</span> <span class="mi">1</span><span class="p">]</span>

        <span class="c1"># 2. Samples from the causal model based on the counterfactual race</span>
        <span class="n">lr_cf</span> <span class="o">=</span> <span class="n">estimator</span><span class="p">()</span>
        <span class="n">lr_cf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_cf</span><span class="p">[</span><span class="n">X</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">),</span> <span class="n">df</span><span class="p">[</span><span class="n">target</span><span class="p">])</span>
        <span class="n">df_cf</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;preds_cf&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr_cf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">df_cf</span><span class="p">[</span><span class="n">X</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">))[:,</span> <span class="mi">1</span><span class="p">]</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># 1. Samples from the causal model based on the observed race</span>
        <span class="n">lr_observed</span> <span class="o">=</span> <span class="n">estimator</span><span class="p">()</span>
        <span class="n">lr_observed</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_obs</span><span class="p">[</span><span class="n">X</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">),</span> <span class="n">df</span><span class="p">[</span><span class="n">target</span><span class="p">])</span>
        <span class="n">df_obs</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;preds&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr_observed</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">df_obs</span><span class="p">[</span><span class="n">X</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">))</span>

        <span class="c1"># 2. Samples from the causal model based on the counterfactual race</span>
        <span class="n">lr_cf</span> <span class="o">=</span> <span class="n">estimator</span><span class="p">()</span>
        <span class="n">lr_cf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_cf</span><span class="p">[</span><span class="n">X</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">),</span> <span class="n">df</span><span class="p">[</span><span class="n">target</span><span class="p">])</span>
        <span class="n">df_cf</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;preds_cf&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr_cf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">df_cf</span><span class="p">[</span><span class="n">X</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">))</span>

    <span class="n">query</span> <span class="o">=</span> <span class="s2">&quot; and &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">protected_attr</span><span class="si">}</span><span class="s2"> == </span><span class="si">{</span><span class="n">disadvantage_group</span><span class="p">[</span><span class="n">protected_attr</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">for</span> <span class="n">protected_attr</span> <span class="ow">in</span> <span class="n">protected_attrs</span>
    <span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">query</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="n">counterfactual_fairness</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">df_obs</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">mask</span><span class="p">][</span><span class="s2">&quot;preds&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">-</span> <span class="n">df_cf</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">mask</span><span class="p">][</span><span class="s2">&quot;preds_cf&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_cache</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">counterfactual_fairness</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">counterfactual_fairness</span><span class="p">,</span> <span class="n">df_obs</span><span class="p">,</span> <span class="n">df_cf</span>

<span class="k">def</span><span class="w"> </span><span class="nf">plot_counterfactual_fairness</span><span class="p">(</span>
    <span class="n">df_obs</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">df_cf</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">mask</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span>
    <span class="n">counterfactual_fairness</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
    <span class="n">legend_observed</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">legend_counterfactual</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">target</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">title</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plots counterfactual fairness comparing observed and counterfactual samples.</span>

<span class="sd">    Args:</span>
<span class="sd">        df_obs (pd.DataFrame): DataFrame containing observed samples.</span>
<span class="sd">        df_cf (pd.DataFrame): DataFrame containing counterfactual samples.</span>
<span class="sd">        mask (pd.Series): Boolean mask for selecting specific samples from the DataFrames.</span>
<span class="sd">        counterfactual_fairness (Union[int, float]): The counterfactual fairness metric.</span>
<span class="sd">        legend_observed (str): Legend label for the observed samples.</span>
<span class="sd">        legend_counterfactual (str): Legend label for the counterfactual samples.</span>
<span class="sd">        target (str): Name of the target variable to be plotted on the x-axis.</span>
<span class="sd">        title (str): Title of the plot.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None: The function displays the plot.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span>
        <span class="n">df_obs</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;preds&quot;</span><span class="p">][</span><span class="n">mask</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">legend_observed</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span>
    <span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span>
        <span class="n">df_cf</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;preds_cf&quot;</span><span class="p">][</span><span class="n">mask</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">legend_counterfactual</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;orange&quot;</span>
    <span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>

    <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Counterfactual Fairness </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">counterfactual_fairness</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span><span class="w"> </span><span class="nf">_wrapper_lambda_fn</span><span class="p">(</span><span class="n">val</span><span class="p">):</span>
    <span class="k">return</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">val</span>
</pre></div>
</div>
</div>
</section>
</section>
</section>
<section id="1.-Load-and-Clean-the-Dataset">
<h1>1. Load and Clean the Dataset<a class="headerlink" href="#1.-Load-and-Clean-the-Dataset" title="Permalink to this heading">#</a></h1>
<p>Kusner et al. (2018) use a survey, conducted by the Law School Admission Council, spanning 163 law schools in the United States, gathering data from 21,790 law students. The dataset used within this case study was originally collected for a study called <a class="reference external" href="https://eric.ed.gov/?id=ED469370">‘LSAC National Longitudinal Bar Passage Study. LSAC Research Report Series’</a> by Linda Wightman in 1998. The survey includes the following details:</p>
<ul class="simple">
<li><p>entrance exam scores (LSAT)</p></li>
<li><p>pre-law school grade-point average (GPA)</p></li>
<li><p>average grade in the first year (FYA).</p></li>
</ul>
<p>It also includes protected attributes like:</p>
<ul class="simple">
<li><p>Race</p></li>
<li><p>Sex</p></li>
</ul>
<p>For the purpose of this example, we will focus on the difference in outcomes only between the White and Black sub-groups and limit the dataset to a random sample of 5000 individuals:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;datasets/law_data.csv&quot;</span><span class="p">)</span>

<span class="n">df</span><span class="p">[</span><span class="s2">&quot;Gender&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;sex&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="mi">2</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="mi">1</span><span class="p">})</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;Race&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;race&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">({</span><span class="s2">&quot;White&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Black&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">})</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>

<span class="n">df</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">df</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;race==&#39;White&#39; or race==&#39;Black&#39;&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;UGPA&quot;</span><span class="p">:</span> <span class="s2">&quot;GPA&quot;</span><span class="p">,</span> <span class="s2">&quot;LSAT&quot;</span><span class="p">:</span> <span class="s2">&quot;LSAT&quot;</span><span class="p">,</span> <span class="s2">&quot;ZFYA&quot;</span><span class="p">:</span> <span class="s2">&quot;avg_grade&quot;</span><span class="p">})[</span>
        <span class="p">[</span><span class="s2">&quot;Race&quot;</span><span class="p">,</span> <span class="s2">&quot;Gender&quot;</span><span class="p">,</span> <span class="s2">&quot;GPA&quot;</span><span class="p">,</span> <span class="s2">&quot;LSAT&quot;</span><span class="p">,</span> <span class="s2">&quot;avg_grade&quot;</span><span class="p">]</span>
    <span class="p">]</span>
    <span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">df_sample</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">5000</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">df_sample</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Race</th>
      <th>Gender</th>
      <th>GPA</th>
      <th>LSAT</th>
      <th>avg_grade</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.2</td>
      <td>37.5</td>
      <td>-0.04</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.8</td>
      <td>38.0</td>
      <td>0.21</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.7</td>
      <td>41.0</td>
      <td>1.55</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.4</td>
      <td>40.0</td>
      <td>-1.11</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>3.7</td>
      <td>39.0</td>
      <td>0.26</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>Given this data, a school may wish to predict if an applicant will have a high FYA. The school would also like to make sure these predictions are not biased by an individual’s race and sex. However, the LSAT, GPA, and FYA scores, may be biased due to social factors. So how can we determine the degree to which such a predictie model may be biased for a particular individual? Using Counterfactual Fairness.</p>
</section>
<section id="2.-A-Formal-Definition-of-Counterfactual-Fairness">
<h1>2. A Formal Definition of Counterfactual Fairness<a class="headerlink" href="#2.-A-Formal-Definition-of-Counterfactual-Fairness" title="Permalink to this heading">#</a></h1>
<p>Counterfactual fairness requires that, for each person in the population, the predicted value remain the same even if that person had different protected attributes in a causal sense. More formally, <span class="math notranslate nohighlight">\(\hat{Y}\)</span> is counterfactually fair if under any context X = x and A = a:</p>
<div class="math notranslate nohighlight">
\[P(\hat{Y}_{a}(U) = y | X = x, A = a) = P(\hat{Y}_{a'}(U) = y | X = x, A = a)\]</div>
<p>for all y and for any value a’ attainable by A. This concept is closely connected to actual causes or token causality. In essence, for fairness, A should not be a direct cause of <span class="math notranslate nohighlight">\(\hat{Y}\)</span> in any specific instance i.e. altering A while keeping non-causally dependent factors constant should not alter the distribution of <span class="math notranslate nohighlight">\(\hat{Y}\)</span>. For an individual i, the difference between Y generated from various counterfactual worlds can be understood as a measure of similarity.</p>
<section id="2.1-Measuring-Counterfactual-Fairness">
<h2>2.1 Measuring Counterfactual Fairness<a class="headerlink" href="#2.1-Measuring-Counterfactual-Fairness" title="Permalink to this heading">#</a></h2>
<p>In a SCM M, the state of any observable variable (Vi) is fully determined by the background variables (U) and structural equations (F). Thus, given a fully-specified set of equations, using an SCM we can construct counterfactuals. That is</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&quot;we can compute what (the distribution of) any of the variables would have been had certain other variables been different, other things being equal. For instance, given the causal model we can ask “Would individual i have graduated (Y = 1) if they hadn’t had a job?”, even if they did not actually graduate in the dataset.&quot; - (Russell et. al. , 2017)
</pre></div>
</div>
<p>Given a SCM M and evidence E (subset of V), counterfactuals are constructed (i.e. inferred) in three steps:</p>
<ol class="arabic simple">
<li><p><strong>Abduction</strong>: i.e. using M, adjusting noise variables to be consistent with the observed evidence E. More formally, given E and a prior distribution P(U), compute the values of the set of unobserved variables U given M. For non-deterministic models (as is the case for most causal models in the literature), compute the posterior distribution P(U|E=e).</p></li>
<li><p><strong>Action</strong>: Perform do-intervention on Z (i.e. do(Zi = z)), resulting in the intervened SCM model M’.</p></li>
<li><p><strong>Prediction</strong>: Using the intervened model M’ and P(U|E=e), compute the counterfactual value of V (or P(V |E=e)).</p></li>
</ol>
</section>
</section>
<section id="3.-Measuring-Counterfactual-Fairness-using-DoWhy">
<h1>3. Measuring Counterfactual Fairness using DoWhy<a class="headerlink" href="#3.-Measuring-Counterfactual-Fairness-using-DoWhy" title="Permalink to this heading">#</a></h1>
<p>Algorithmically, to empirically test whether a model is counterfactually fair:</p>
<ul class="simple">
<li><p><strong>Step 1 - Define a causal model</strong> based on a causal DAG</p></li>
<li><p><strong>Step 2 - Generate counterfactual samples</strong>: Using <code class="docutils literal notranslate"><span class="pre">gcm.counterfactual_samples</span></code> , generate two sets of samples from the model:</p>
<ol class="loweralpha simple">
<li><p>one using the observed values of the protected attributes (<code class="docutils literal notranslate"><span class="pre">df_obs</span></code>)</p></li>
<li><p>one using counterfactual values of the protected attributes (<code class="docutils literal notranslate"><span class="pre">df_cf</span></code>)</p></li>
</ol>
</li>
<li><p><strong>Step 3 - Fit estimators using sampled data</strong>: Fit models to both the original and counterfactual sampled data and plot the distribution of the predicted target generated by the two models. <em>If the distributions overlap, the estimator is counterfactually fair else not.</em></p></li>
</ul>
<p>Given a dataset with protected / proxy attributes and a causal DAG , we can use the <code class="docutils literal notranslate"><span class="pre">analyse_counterfactual_fairness</span></code> function to measure counterfactual fairness at both the individual and aggregate level. In this example, we create the causal DAG based on the causal DAG provided in Kusner et al. (2018).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dag</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">&quot;Race&quot;</span><span class="p">,</span> <span class="s2">&quot;GPA&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Race&quot;</span><span class="p">,</span> <span class="s2">&quot;LSAT&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Race&quot;</span><span class="p">,</span> <span class="s2">&quot;avg_grade&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Gender&quot;</span><span class="p">,</span> <span class="s2">&quot;GPA&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Gender&quot;</span><span class="p">,</span> <span class="s2">&quot;LSAT&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;Gender&quot;</span><span class="p">,</span> <span class="s2">&quot;avg_grade&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;GPA&quot;</span><span class="p">,</span> <span class="s2">&quot;avg_grade&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;LSAT&quot;</span><span class="p">,</span> <span class="s2">&quot;avg_grade&quot;</span><span class="p">),</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">analyse_counterfactual_fairness</span></code> method also accepts as inputs:</p>
<ul class="simple">
<li><p>the name of the target variable (<code class="docutils literal notranslate"><span class="pre">target</span></code> here avg_grade)</p></li>
<li><p>the input dataset (<code class="docutils literal notranslate"><span class="pre">df</span></code>)</p></li>
<li><p>an unfitted sklearn estimator (<code class="docutils literal notranslate"><span class="pre">estimator</span></code>; here LinearRegression)-</p></li>
<li><p>list of protected attributes (<code class="docutils literal notranslate"><span class="pre">protected_attrs</span></code>)</p></li>
<li><p>the list of input feature names (<code class="docutils literal notranslate"><span class="pre">X</span></code>)</p></li>
<li><p>a dictionary specifying the unique identifying label of the disadvantaged group for each protected group (<code class="docutils literal notranslate"><span class="pre">disadvantage_group</span></code>).</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">target</span> <span class="o">=</span> <span class="s2">&quot;avg_grade&quot;</span>
<span class="n">disadvantage_group</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;Race&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
<span class="n">protected_attrs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Race&quot;</span><span class="p">]</span>
<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;GPA&quot;</span><span class="p">,</span> <span class="s2">&quot;LSAT&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<section id="3.1-Univariate-Analysis">
<h2>3.1 Univariate Analysis<a class="headerlink" href="#3.1-Univariate-Analysis" title="Permalink to this heading">#</a></h2>
<p>Now, we are ready to call the method <code class="docutils literal notranslate"><span class="pre">analyse_counterfactual_fairness</span></code> to carry out counterfactual fairness analysis along the Race dimension:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;df&quot;</span><span class="p">:</span> <span class="n">df_sample</span><span class="p">,</span>
    <span class="s2">&quot;dag&quot;</span><span class="p">:</span> <span class="n">dag</span><span class="p">,</span>
    <span class="s2">&quot;estimator&quot;</span><span class="p">:</span> <span class="n">LinearRegression</span><span class="p">,</span>
    <span class="s2">&quot;protected_attrs&quot;</span><span class="p">:</span> <span class="n">protected_attrs</span><span class="p">,</span>
    <span class="s2">&quot;X&quot;</span><span class="p">:</span> <span class="n">features</span><span class="p">,</span>
    <span class="s2">&quot;target&quot;</span><span class="p">:</span> <span class="n">target</span><span class="p">,</span>
    <span class="s2">&quot;disadvantage_group&quot;</span><span class="p">:</span> <span class="n">disadvantage_group</span><span class="p">,</span>
    <span class="s2">&quot;return_cache&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">counterfactual_fairness</span><span class="p">,</span> <span class="n">df_obs</span><span class="p">,</span> <span class="n">df_cf</span> <span class="o">=</span> <span class="n">analyse_counterfactual_fairness</span><span class="p">(</span><span class="o">**</span><span class="n">config</span><span class="p">)</span>
<span class="n">counterfactual_fairness</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Fitting causal mechanism of node Gender: 100%|██████████| 5/5 [00:00&lt;00:00, 106.71it/s]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="math notranslate nohighlight">
$\displaystyle -0.439340713866072$</div></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">df_obs</span></code> contains the predicted values for each individual given the observed value of their protected attribute in the real world.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_obs</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Race</th>
      <th>Gender</th>
      <th>GPA</th>
      <th>LSAT</th>
      <th>avg_grade</th>
      <th>preds</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.2</td>
      <td>37.5</td>
      <td>-0.04</td>
      <td>0.151407</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.8</td>
      <td>38.0</td>
      <td>0.21</td>
      <td>0.064937</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.7</td>
      <td>41.0</td>
      <td>1.55</td>
      <td>0.154109</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.4</td>
      <td>40.0</td>
      <td>-1.11</td>
      <td>0.300614</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>3.7</td>
      <td>39.0</td>
      <td>0.26</td>
      <td>0.341382</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">df_cf</span></code> contains the predicted values for each individual given the counterfactual value of their protected attribute in the real world. Here, since the only variable we are intervening on is Race, we see that each individual’s Race has been changed from 0 to 1.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_cf</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Race</th>
      <th>Gender</th>
      <th>GPA</th>
      <th>LSAT</th>
      <th>avg_grade</th>
      <th>preds_cf</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>2.830057</td>
      <td>29.072266</td>
      <td>-1.254030</td>
      <td>0.132622</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>2.430057</td>
      <td>29.572266</td>
      <td>-0.869318</td>
      <td>0.107303</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>2.330057</td>
      <td>32.572266</td>
      <td>0.458796</td>
      <td>0.115805</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>3.030057</td>
      <td>31.572266</td>
      <td>-2.434970</td>
      <td>0.159469</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>3.330057</td>
      <td>31.343140</td>
      <td>-0.907970</td>
      <td>0.179211</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_counterfactual_fairness</span><span class="p">(</span>
    <span class="n">df_obs</span><span class="o">=</span><span class="n">df_obs</span><span class="p">,</span>
    <span class="n">df_cf</span><span class="o">=</span><span class="n">df_cf</span><span class="p">,</span>
    <span class="n">mask</span><span class="o">=</span><span class="p">(</span><span class="n">df_sample</span><span class="p">[</span><span class="s2">&quot;Race&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">counterfactual_fairness</span><span class="o">=</span><span class="n">counterfactual_fairness</span><span class="p">,</span>
    <span class="n">legend_observed</span><span class="o">=</span><span class="s2">&quot;Observed Samples (Race=Black)&quot;</span><span class="p">,</span>
    <span class="n">legend_counterfactual</span><span class="o">=</span><span class="s2">&quot;Counterfactual Samples (Race=White)&quot;</span><span class="p">,</span>
    <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Black -&gt; White&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_counterfactual_fairness_dowhy_16_0.png" src="../_images/example_notebooks_counterfactual_fairness_dowhy_16_0.png" />
</div>
</div>
<p>Examining the results for the example at hand in Figure 1, we see that the observed and counterfactual distributions don’t overlap. We see that changing the race of the black subgroup to the white subgroup shifts the distribution of <span class="math notranslate nohighlight">\(\hat{Y}\)</span> to the right i.e. increases the avg_grade by ~0.50 on average. Thus, the fitted estimator can concluded to be not counterfactually fair.</p>
</section>
<section id="3.2-Intersectional-Analysis">
<h2>3.2 Intersectional Analysis<a class="headerlink" href="#3.2-Intersectional-Analysis" title="Permalink to this heading">#</a></h2>
<p>We can further extend the analysis intersectionally, by examining the implication of multipleprotected attriutes on counterfactual fairness together. Here, we use the two protected attributes available to us - <code class="docutils literal notranslate"><span class="pre">[&quot;Race&quot;,&quot;Gender&quot;]</span></code> - to carry out intersectional counterfactual fairness analysis to determine how counterfactually fair the estimator is for Black Females:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">disadvantage_group</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;Race&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;Gender&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
<span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;df&quot;</span><span class="p">:</span> <span class="n">df_sample</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="s2">&quot;estimator&quot;</span><span class="p">:</span> <span class="n">LinearRegression</span><span class="p">,</span>
    <span class="s2">&quot;protected_attrs&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;Race&quot;</span><span class="p">,</span> <span class="s2">&quot;Gender&quot;</span><span class="p">],</span>
    <span class="s2">&quot;dag&quot;</span><span class="p">:</span> <span class="n">dag</span><span class="p">,</span>
    <span class="s2">&quot;X&quot;</span><span class="p">:</span> <span class="n">features</span><span class="p">,</span>
    <span class="s2">&quot;target&quot;</span><span class="p">:</span> <span class="s2">&quot;avg_grade&quot;</span><span class="p">,</span>
    <span class="s2">&quot;return_cache&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="s2">&quot;disadvantage_group&quot;</span><span class="p">:</span> <span class="n">disadvantage_group</span><span class="p">,</span>
    <span class="s2">&quot;intersectional&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">counterfactual_fairness</span><span class="p">,</span> <span class="n">df_obs</span><span class="p">,</span> <span class="n">df_cf</span> <span class="o">=</span> <span class="n">analyse_counterfactual_fairness</span><span class="p">(</span><span class="o">**</span><span class="n">config</span><span class="p">)</span>
<span class="n">counterfactual_fairness</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Fitting causal mechanism of node Gender: 100%|██████████| 5/5 [00:00&lt;00:00, 463.67it/s]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="math notranslate nohighlight">
$\displaystyle -0.42446745281168$</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_counterfactual_fairness</span><span class="p">(</span>
    <span class="n">df_obs</span><span class="o">=</span><span class="n">df_obs</span><span class="p">,</span>
    <span class="n">df_cf</span><span class="o">=</span><span class="n">df_cf</span><span class="p">,</span>
    <span class="n">mask</span><span class="o">=</span><span class="p">((</span><span class="n">df_sample</span><span class="p">[</span><span class="s2">&quot;Race&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df_sample</span><span class="p">[</span><span class="s2">&quot;Gender&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">),</span>
    <span class="n">counterfactual_fairness</span><span class="o">=</span><span class="n">counterfactual_fairness</span><span class="p">,</span>
    <span class="n">legend_observed</span><span class="o">=</span><span class="s2">&quot;Observed Samples (Race=Black, Gender=Female)&quot;</span><span class="p">,</span>
    <span class="n">legend_counterfactual</span><span class="o">=</span><span class="s2">&quot;Counterfactual Samples (Race=White, Gender=Male)&quot;</span><span class="p">,</span>
    <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;(Black, Female) -&gt; (White, Male)&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_counterfactual_fairness_dowhy_19_0.png" src="../_images/example_notebooks_counterfactual_fairness_dowhy_19_0.png" />
</div>
</div>
<p>Examining the results of the intersectional analysis in Figure 2, we see that the observed and counterfactual distributions don’t overlap at all. Changing the race and gender of the black females to the white males shifts the distribution of <span class="math notranslate nohighlight">\(\hat{Y}\)</span> for the black,female sub-group to the right i.e. increases the avg_grade by ~0.50 on average. Thus, the fitted estimator can concluded to be not counterfactually fair intersectionally.</p>
</section>
<section id="3.3-Some-Additional-Uses-of-the-Counterfactuals-df_obs-,-df_cf-for-Fairness">
<h2>3.3 Some Additional Uses of the Counterfactuals <code class="docutils literal notranslate"><span class="pre">df_obs</span></code> , <code class="docutils literal notranslate"><span class="pre">df_cf</span></code> for Fairness<a class="headerlink" href="#3.3-Some-Additional-Uses-of-the-Counterfactuals-df_obs-,-df_cf-for-Fairness" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Counterfactual values of Y (constructed using a set of fair causal models) can be used as a fair target to train the model with, in the presence of historically biased labels Y.</p></li>
<li><p>Train an estimator to be counterfactually fair by using an optimization routine that applies a penalty for a given individual i in proportion to the (average) difference in Y across counterfactual worlds for that individual i. For instance, if for an individual i the outcome Y is very different across counterfactual worlds, then that sample i will increase the loss by a proportionately higher amount. Conversely, if for an individual j the outcome Y is similar across counterfactual worlds,
then that sample i will increase the loss by a proportionately lower amount (See Russell, Chris et al., 2017 for more details).</p></li>
</ul>
</section>
</section>
<section id="4.-Limitation-of-Counterfactual-Fairness">
<h1>4. Limitation of Counterfactual Fairness<a class="headerlink" href="#4.-Limitation-of-Counterfactual-Fairness" title="Permalink to this heading">#</a></h1>
<p>There maybe disagreements about the “correct” causal model due to:</p>
<ul class="simple">
<li><p>Changing the structure of the DAG, e.g. adding an edge</p></li>
<li><p>Changing the latent variables, e.g. changing the function generating a node to have a different signal vs. noise decomposition</p></li>
<li><p>Preventing certain paths from propagating counterfactual values</p></li>
</ul>
<p>The literature suggests achieving counterfactual fairness under multiple competing casual models as a solution to the above. Russell et. al. , (2017) put forward one such solution called the “Multi-World Fairness Algorithm”.</p>
</section>
<section id="References">
<h1>References<a class="headerlink" href="#References" title="Permalink to this heading">#</a></h1>
<ul class="simple">
<li><p>Kusner, Matt et al. Counterfactual Fairness. 2018, <a class="reference external" href="https://arxiv.org/pdf/1703.06856.pdf">https://arxiv.org/pdf/1703.06856.pdf</a></p></li>
<li><p>Russell, Chris et al. When Worlds Collide: Integrating Different Counterfactual Assumptions In Fairness. 2017, <a class="reference external" href="https://proceedings.neurips.cc/paper/2017/file/1271a7029c9df08643b631b02cf9e116-Paper.pdf">https://proceedings.neurips.cc/paper/2017/file/1271a7029c9df08643b631b02cf9e116-Paper.pdf</a></p></li>
</ul>
</section>
<section id="Appendix-:-Fairness-Through-Unawareness-(FTU)-creates-A-Counterfactually-Unfair-Estimator">
<h1>Appendix : Fairness Through Unawareness (FTU) creates A Counterfactually Unfair Estimator<a class="headerlink" href="#Appendix-:-Fairness-Through-Unawareness-(FTU)-creates-A-Counterfactually-Unfair-Estimator" title="Permalink to this heading">#</a></h1>
<p>To demonstrate that <strong>“Aware” linear regression is always counterfactually fair but FTU makes it counterfactually unfair</strong>, we build one “aware” linear regression and copare it with the “unaware” linear regression constructed Fig.1.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;df&quot;</span><span class="p">:</span> <span class="n">df_sample</span><span class="p">,</span>
    <span class="s2">&quot;estimator&quot;</span><span class="p">:</span> <span class="n">LinearRegression</span><span class="p">,</span>
    <span class="s2">&quot;protected_attrs&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;Race&quot;</span><span class="p">],</span>
    <span class="s2">&quot;dag&quot;</span><span class="p">:</span> <span class="n">dag</span><span class="p">,</span>
    <span class="s2">&quot;X&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;GPA&quot;</span><span class="p">,</span> <span class="s2">&quot;LSAT&quot;</span><span class="p">,</span> <span class="s2">&quot;Race&quot;</span><span class="p">,</span> <span class="s2">&quot;Gender&quot;</span><span class="p">],</span>
    <span class="s2">&quot;target&quot;</span><span class="p">:</span> <span class="s2">&quot;avg_grade&quot;</span><span class="p">,</span>
    <span class="s2">&quot;return_cache&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="s2">&quot;disadvantage_group&quot;</span><span class="p">:</span> <span class="n">disadvantage_group</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">counterfactual_fairness_aware</span><span class="p">,</span> <span class="n">df_obs_aware</span><span class="p">,</span> <span class="n">df_cf_aware</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">analyse_counterfactual_fairness</span><span class="p">(</span><span class="o">**</span><span class="n">config</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">counterfactual_fairness_aware</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Fitting causal mechanism of node Gender: 100%|██████████| 5/5 [00:00&lt;00:00, 293.73it/s]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="math notranslate nohighlight">
$\displaystyle 1.22124532708767 \cdot 10^{-15}$</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_counterfactual_fairness</span><span class="p">(</span>
    <span class="n">df_obs</span><span class="o">=</span><span class="n">df_obs_aware</span><span class="p">,</span>
    <span class="n">df_cf</span><span class="o">=</span><span class="n">df_cf_aware</span><span class="p">,</span>
    <span class="n">mask</span><span class="o">=</span><span class="p">(</span><span class="n">df_sample</span><span class="p">[</span><span class="s2">&quot;Race&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">counterfactual_fairness</span><span class="o">=</span><span class="n">counterfactual_fairness_aware</span><span class="p">,</span>
    <span class="n">legend_observed</span><span class="o">=</span><span class="s2">&quot;Observed Samples (Race=Black)&quot;</span><span class="p">,</span>
    <span class="n">legend_counterfactual</span><span class="o">=</span><span class="s2">&quot;Counterfactual Samples (Race=White)&quot;</span><span class="p">,</span>
    <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Black -&gt; White&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/example_notebooks_counterfactual_fairness_dowhy_23_0.png" src="../_images/example_notebooks_counterfactual_fairness_dowhy_23_0.png" />
</div>
</div>
<p>Comparing Figure 1 and Figure 3, the comparitive plot of the observed counterfactual samples <code class="docutils literal notranslate"><span class="pre">df_obs</span></code> and perturbed counterfactual samples <code class="docutils literal notranslate"><span class="pre">df_cf</span></code>, shows that:</p>
<ol class="arabic simple">
<li><p>for the “aware” linear regression in figure 3, the two distributions overlap. Thus, the estimator is counterfactually fair.</p></li>
<li><p>for the “unaware” linear regression in figure 1, the two distributions are quite distinct and do not overlap, suggesting that the estimator is counterfactually unfair i.e. regressing avg_grade on <em>only</em> GPA and LSAT makes the estimator counterfactually unfair.</p></li>
</ol>
<p>Notable,it can formally be shown that, in general “Regressing Y on X alone obeys the FTU criterion but is not counterfactually fair, so omitting A (FTU) may introduce unfairness into an otherwise fair world”. (Kusner et al. 2018)</p>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="gcm_falsify_dag.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Falsification of User-Given Directed Acyclic Graphs</p>
      </div>
    </a>
    <a class="right-next"
       href="sales_attribution_intervention.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Causal attribution to sales growth and spend intervention</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">

  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Counterfactual Fairness</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#When-to-apply-counterfactual-fairness?">When to apply counterfactual fairness?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#What-is-required-to-estimate-counterfactual-fairness?">What is required to estimate counterfactual fairness?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Notation">Notation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#1.-Load-and-Clean-the-Dataset">1. Load and Clean the Dataset</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#2.-A-Formal-Definition-of-Counterfactual-Fairness">2. A Formal Definition of Counterfactual Fairness</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#2.1-Measuring-Counterfactual-Fairness">2.1 Measuring Counterfactual Fairness</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#3.-Measuring-Counterfactual-Fairness-using-DoWhy">3. Measuring Counterfactual Fairness using DoWhy</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#3.1-Univariate-Analysis">3.1 Univariate Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#3.2-Intersectional-Analysis">3.2 Intersectional Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#3.3-Some-Additional-Uses-of-the-Counterfactuals-df_obs-,-df_cf-for-Fairness">3.3 Some Additional Uses of the Counterfactuals <code class="docutils literal notranslate"><span class="pre">df_obs</span></code> , <code class="docutils literal notranslate"><span class="pre">df_cf</span></code> for Fairness</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#4.-Limitation-of-Counterfactual-Fairness">4. Limitation of Counterfactual Fairness</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#References">References</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Appendix-:-Fairness-Through-Unawareness-(FTU)-creates-A-Counterfactually-Unfair-Estimator">Appendix : Fairness Through Unawareness (FTU) creates A Counterfactually Unfair Estimator</a></li>
</ul>

  </nav></div>

  <div class="sidebar-secondary-item">

  <div class="tocsection sourcelink">
    <a href="../_sources/example_notebooks/counterfactual_fairness_dowhy.ipynb.txt">
      <i class="fa-solid fa-file-lines"></i> Show Source
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2022, PyWhy contributors.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.1.2.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.14.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>